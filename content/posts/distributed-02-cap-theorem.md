---
title: "åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€ï¼šCAPç†è®ºæ·±åº¦è§£æä¸å®è·µåº”ç”¨"
date: 2024-09-19T11:00:00+08:00
draft: false
tags: ["åˆ†å¸ƒå¼ç³»ç»Ÿ", "CAPç†è®º", "ä¸€è‡´æ€§", "å¯ç”¨æ€§", "åˆ†åŒºå®¹é”™"]
categories: ["åˆ†å¸ƒå¼ç³»ç»Ÿ"]
author: "lesshash"
description: "æ·±å…¥ç†è§£CAPç†è®ºï¼šåˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡ä¸­çš„åŸºæœ¬çº¦æŸï¼Œä»ç†è®ºåŸºç¡€åˆ°å®é™…ç³»ç»Ÿæ¶æ„é€‰æ‹©çš„å®Œæ•´æŒ‡å—"
---

## å¼•è¨€

æƒ³è±¡ä¸€ä¸‹ï¼Œä½ åœ¨ä½¿ç”¨å¾®ä¿¡è½¬è´¦æ—¶ï¼Œçªç„¶é‡åˆ°ç½‘ç»œæ•…éšœã€‚ä½ ä¼šå¸Œæœ›ï¼š
- ğŸ”’ **æ•°æ®ä¸€è‡´**ï¼šä½ å’Œæœ‹å‹çœ‹åˆ°çš„è´¦æˆ·ä½™é¢éƒ½æ˜¯æ­£ç¡®çš„
- ğŸš€ **ç³»ç»Ÿå¯ç”¨**ï¼šé€ç»™èƒ½å¤Ÿæ­£å¸¸å¤„ç†ä½ çš„è½¬è´¦è¯·æ±‚
- ğŸŒ **ç½‘ç»œå®¹é”™**ï¼šå³ä½¿éƒ¨åˆ†ç½‘ç»œå‡ºç°é—®é¢˜ï¼Œç³»ç»Ÿä»èƒ½æ­£å¸¸å·¥ä½œ

ä½†æ˜¯CAPç†è®ºå‘Šè¯‰æˆ‘ä»¬ï¼š**è¿™ä¸‰ä¸ªç›®æ ‡æ— æ³•åŒæ—¶å®ç°ï¼**

CAPç†è®ºæ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡ä¸­æœ€é‡è¦çš„ç†è®ºåŸºç¡€ï¼Œå®ƒæ­ç¤ºäº†ä¸€ä¸ªæ®‹é…·çš„ç°å®ï¼šåœ¨é¢å¯¹ç½‘ç»œåˆ†åŒºæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»åœ¨ä¸€è‡´æ€§å’Œå¯ç”¨æ€§ä¹‹é—´åšå‡ºè‰°éš¾çš„é€‰æ‹©ã€‚

### ğŸ¯ ä¸ºä»€ä¹ˆè¦å­¦ä¹ CAPç†è®ºï¼Ÿ

- ğŸ¢ **æ¶æ„å†³ç­–**ï¼šå¸®åŠ©æ¶æ„å¸ˆåšå‡ºæ˜æ™ºçš„æŠ€æœ¯é€‰å‹
- ğŸ’° **ä¸šåŠ¡ç†è§£**ï¼šæ˜ç™½ä¸åŒä¸šåŠ¡åœºæ™¯çš„æŠ€æœ¯è¦æ±‚
- ğŸ•§ **é—®é¢˜è¯Šæ–­**ï¼šå¿«é€Ÿå®šä½åˆ†å¸ƒå¼ç³»ç»Ÿé—®é¢˜çš„æ ¹æœ¬åŸå› 
- ğŸš€ **æ€§èƒ½ä¼˜åŒ–**ï¼šæ ¹æ®ä¸šåŠ¡ç‰¹ç‚¹è¿›è¡Œç²¾å‡†ä¼˜åŒ–

## ğŸ”¬ CAPç†è®ºæ·±åº¦å‰–æ

### ğŸ’« ä¸‰å¤§ç‰¹æ€§å…¨è§£æ

è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªç”ŸåŠ¨çš„æ¯”å–»æ¥ç†è§£CAPä¸‰è¦ç´ ï¼š

#### ğŸ¦ CAPä¸‰è¦ç´  - éŠ€è¡Œç³»ç»Ÿç±»æ¯”

| ç‰¹æ€§ | å®šä¹‰ | é“¶è¡Œç³»ç»Ÿç±»æ¯” | æ ¸å¿ƒè¦æ±‚ |
|------|------|-------------|----------|
| **ğŸ”’ Consistency<br/>ä¸€è‡´æ€§** | æ‰€æœ‰èŠ‚ç‚¹åœ¨åŒä¸€æ—¶åˆ»çœ‹åˆ°ç›¸åŒçš„æ•°æ® | å°±åƒéŠ€è¡Œè´¦æˆ·ï¼š<br/>ä½ åœ¨åŒ—äº¬å’Œä¸Šæµ·æŸ¥è¯¢<br/>ä½™é¢å¿…é¡»å®Œå…¨ä¸€æ · | æ•°æ®ç»Ÿä¸€æ€§ |
| **ğŸš€ Availability<br/>å¯ç”¨æ€§** | ç³»ç»Ÿå§‹ç»ˆä¿æŒå¯è®¿é—®çŠ¶æ€ | å°±åƒATMæœºï¼š<br/>24å°æ—¶éšæ—¶å¯ä»¥<br/>å–é’±å’ŒæŸ¥è¯¢ | æœåŠ¡æŒç»­æ€§ |
| **ğŸŒ Partition Tolerance<br/>åˆ†åŒºå®¹é”™** | ç½‘ç»œåˆ†åŒºæ—¶ç³»ç»Ÿä»å¯è¿è¡Œ | å°±åƒç½‘ç‚¹é—´é€šä¿¡ï¼š<br/>å³ä½¿ç”µç¼†æ–­äº†ï¼Œ<br/>ä»èƒ½éƒ¨åˆ†æœåŠ¡ | å®¹é”™èƒ½åŠ› |

**ä¸‰è€…å…³ç³»ï¼š** è¿™ä¸‰ä¸ªç‰¹æ€§ä¸èƒ½åŒæ—¶æ»¡è¶³ï¼Œå¿…é¡»åœ¨å…¶ä¸­è¿›è¡Œæƒè¡¡ã€‚

### ğŸ“† å†å²èƒŒæ™¯ä¸å‘å±•

| æ—¶é—´ | é‡Œç¨‹ç¢‘ | é‡è¦æ€§ |
|------|----------|---------|
| **2000å¹´** | Eric Breweræå‡ºCAPçŒœæƒ³ | é¦–æ¬¡æå‡ºä¸‰è€…ä¸å¯å…¼å¾—çš„è§‚ç‚¹ |
| **2002å¹´** | Gilbert & Lynchæ•°å­¦è¯æ˜ | ä»çŒœæƒ³å‡çº§ä¸ºå®šç† |
| **2012å¹´** | Breweræ¾„æ¸…è¯¯è§£ | æå‡º"2 of 3"ä¸æ˜¯ç»å¯¹çš„ |
| **ç°åœ¨** | å·¥ç¨‹å®è·µä¸­çš„æŒ‡å¯¼åŸåˆ™ | æŒ‡å¯¼ç°ä»£åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡ |

### ğŸ“Š ç²¾ç¡®å®šä¹‰ä¸è¡¡é‡æ ‡å‡†

```mermaid
flowchart LR
    subgraph ConsistencyTypes ["Consistency ä¸€è‡´æ€§ç±»å‹"]
        C1[Linear Consistency<br/>çº¿æ€§ä¸€è‡´æ€§]
        C2[Sequential Consistency<br/>é¡ºåºä¸€è‡´æ€§]
        C3[Causal Consistency<br/>å› æœä¸€è‡´æ€§]
        C4[Eventual Consistency<br/>æœ€ç»ˆä¸€è‡´æ€§]
    end

    subgraph AvailabilityMetrics ["Availability å¯ç”¨æ€§æŒ‡æ ‡"]
        A1[99.9% = 8.77å°æ—¶/å¹´]
        A2[99.99% = 52.6åˆ†é’Ÿ/å¹´]
        A3[99.999% = 5.26åˆ†é’Ÿ/å¹´]
        A4[99.9999% = 31.6ç§’/å¹´]
    end

    subgraph PartitionTypes ["Partition Tolerance å®¹é”™ç±»å‹"]
        P1[ç½‘ç»œåˆ†åŒº]
        P2[èŠ‚ç‚¹æ•…éšœ]
        P3[æ¶ˆæ¯ä¸¢å¤±]
        P4[å»¶è¿Ÿè¶…æ—¶]
    end
```

### ğŸ”¥ æ ¸å¿ƒå®šç†æ·±åº¦è§£è¯»

**CAPå®šç†**ï¼šåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œä¸€è‡´æ€§(Consistency)ã€å¯ç”¨æ€§(Availability)å’Œåˆ†åŒºå®¹é”™æ€§(Partition Tolerance)è¿™ä¸‰ä¸ªç‰¹æ€§æœ€å¤šåªèƒ½åŒæ—¶æ»¡è¶³å…¶ä¸­ä¸¤ä¸ªã€‚

#### ğŸ² ä¸‰è§’å…³ç³»ä¸æƒè¡¡é€‰æ‹©

```mermaid
flowchart TD
    subgraph TriangleChart ["ä¸‰è§’æƒè¡¡å›¾"]
        A["Consistency<br/>ä¸€è‡´æ€§<br/>100% å‡†ç¡®æ•°æ®"]
        B["Availability<br/>å¯ç”¨æ€§<br/>100% å“åº”ç‡"]
        C["Partition Tolerance<br/>åˆ†åŒºå®¹é”™<br/>100% ç½‘ç»œå®¹é”™"]
    end

    A -.->|"ä¸èƒ½åŒæ—¶å­˜åœ¨"| B
    B -.->|"ä¸èƒ½åŒæ—¶å­˜åœ¨"| C
    C -.->|"ä¸èƒ½åŒæ—¶å­˜åœ¨"| A

    A --> CP["ğŸ‘ CPç³»ç»Ÿ<br/>å¼ºä¸€è‡´ + å®¹é”™<br/>(ç‰ºç‰²å¯ç”¨æ€§)"]
    B --> AP["ğŸŒˆ APç³»ç»Ÿ<br/>å¯ç”¨ + å®¹é”™<br/>(ç‰ºç‰²ä¸€è‡´æ€§)"]
    C --> CA["ğŸ’­ CAç³»ç»Ÿ<br/>ä¸€è‡´ + å¯ç”¨<br/>(ç†è®ºæ¨¡å‹)"]

    CP --> CP_SYSTEMS["é‡‘èäº¤æ˜“<br/>Zookeeper<br/>MongoDB<br/>Redis Cluster"]
    AP --> AP_SYSTEMS["ç¤¾äº¤åº”ç”¨<br/>Cassandra<br/>DynamoDB<br/>CouchDB"]
    CA --> CA_SYSTEMS["å•æœºæ•°æ®åº“<br/>ä¼ ç»Ÿ RDBMS<br/>(ç°å®ä¸­ä¸å­˜åœ¨)"]
```

#### ğŸ¤” ä¸ºä»€ä¹ˆCAç³»ç»Ÿä¸å­˜åœ¨ï¼Ÿ

åœ¨ç°å®ç½‘ç»œä¸­ï¼Œåˆ†åŒºæ˜¯ä¸å¯é¿å…çš„ï¼š
- ğŸ”Œ **ç½‘ç»œç”µç¼†**å¯èƒ½è¢«æŒ–æ–­
- ğŸ”¥ **æœºæˆ¿ç«ç¾**å¯¼è‡´æœåŠ¡å™¨å®•æœº
- ğŸŒŠ **è‡ªç„¶ç¾å®³**å½±å“æ•°æ®ä¸­å¿ƒ
- ğŸ› **è½¯ä»¶Bug**å¯¼è‡´ç¨‹åºå´©æºƒ

å› æ­¤ï¼Œ**Partition Toleranceæ˜¯å¿…é¡»é€‰é¡¹**ï¼ŒçœŸæ­£çš„é€‰æ‹©åªåœ¨CPå’ŒAPä¹‹é—´ï¼

## ğŸ”¬ ç‰¹æ€§è¯¦ç»†åˆ†æä¸å®æˆ˜æŒ‡å—

### 1. ğŸ”’ ä¸€è‡´æ€§ (Consistency) å…¨é¢è§£æ

ä¸€è‡´æ€§è¦æ±‚æ‰€æœ‰èŠ‚ç‚¹åœ¨åŒä¸€æ—¶åˆ»çœ‹åˆ°çš„æ•°æ®æ˜¯ç›¸åŒçš„ã€‚ä½†è¿™å¹¶ä¸æ˜¯ä¸€ä¸ªç®€å•çš„â€œæ˜¯æˆ–å¦â€é—®é¢˜ï¼

#### ğŸŒˆ ä¸€è‡´æ€§å…‰è°±ï¼ˆä»å¼ºåˆ°å¼±ï¼‰

```mermaid
flowchart TD
    subgraph StrongConsistency ["å¼ºä¸€è‡´æ€§ Strong Consistency"]
        SC["çº¿æ€§ä¸€è‡´æ€§<br/>Linearizability<br/><br/>æ•°æ®åº“è½¬è´¦<br/>ä¸€å®šæ˜¯åŸå­æ€§çš„"]
    end

    subgraph MediumConsistency ["ä¸­ç­‰ä¸€è‡´æ€§ Medium Consistency"]
        MC1["é¡ºåºä¸€è‡´æ€§<br/>Sequential Consistency<br/><br/>ç¾¤èŠæ¶ˆæ¯<br/>æ‰€æœ‰äººçœ‹åˆ°çš„é¡ºåºç›¸åŒ"]
        MC2["å› æœä¸€è‡´æ€§<br/>Causal Consistency<br/><br/>æœ‹å‹åœˆç‚¹èµ<br/>å…ˆå‘å¸–å†ç‚¹èµ"]
    end

    subgraph WeakConsistency ["å¼±ä¸€è‡´æ€§ Weak Consistency"]
        WC["æœ€ç»ˆä¸€è‡´æ€§<br/>Eventual Consistency<br/><br/>ç¤¾äº¤åª’ä½“<br/>ç‚¹èµæ•°å»¶è¿Ÿæ›´æ–°OK"]
    end

    SC --> MC1
    MC1 --> MC2
    MC2 --> WC
```

#### ğŸ“ˆ ä¸åŒä¸€è‡´æ€§çº§åˆ«çš„æ€§èƒ½å¯¹æ¯”

| ä¸€è‡´æ€§çº§åˆ« | å»¶è¿Ÿ | åé‡ | é€‚ç”¨åœºæ™¯ | ä»£è¡¨ç³»ç»Ÿ |
|-------------|------|------|-----------|----------|
| **çº¿æ€§ä¸€è‡´** | é«˜ | ä½ | é‡‘èäº¤æ˜“ | ä¼ ç»ŸRDBMS |
| **é¡ºåºä¸€è‡´** | ä¸­ | ä¸­ | ååŒåŠå…¬ | Spanner |
| **å› æœä¸€è‡´** | ä½ | é«˜ | ç¤¾äº¤ç½‘ç»œ | COPS |
| **æœ€ç»ˆä¸€è‡´** | æœ€ä½ | æœ€é«˜ | å†…å®¹åˆ†å‘ | Cassandra |

#### ğŸ’» ä¸€è‡´æ€§æ¨¡å‹å®ç°

```java
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.locks.ReentrantLock;

// ğŸ“Š CAPç†è®ºä¸­çš„ä¸€è‡´æ€§æ¨¡å‹å®ç°
enum ConsistencyLevel {
    LINEARIZABLE("çº¿æ€§ä¸€è‡´æ€§", "æœ€å¼ºä¸€è‡´æ€§ï¼Œå®æ—¶åŒæ­¥"),
    SEQUENTIAL("é¡ºåºä¸€è‡´æ€§", "æ“ä½œé¡ºåºä¸€è‡´ï¼Œå…è®¸å»¶è¿Ÿ"),
    CAUSAL("å› æœä¸€è‡´æ€§", "ä¿è¯å› æœå…³ç³»ï¼Œæ€§èƒ½è¾ƒå¥½"),
    EVENTUAL("æœ€ç»ˆä¸€è‡´æ€§", "æœ€ç»ˆåŒæ­¥ï¼Œæ€§èƒ½æœ€ä½³"),
    WEAK("å¼±ä¸€è‡´æ€§", "æ— ä¸€è‡´æ€§ä¿è¯ï¼Œæœ€é«˜æ€§èƒ½");

    private final String description;
    private final String detail;

    ConsistencyLevel(String description, String detail) {
        this.description = description;
        this.detail = detail;
    }

    public String getDescription() {
        return description;
    }

    public String getDetail() {
        return detail;
    }
}

class DataEntry {
    private String value;
    private long timestamp;
    private String writeId;

    public DataEntry(String value, long timestamp, String writeId) {
        this.value = value;
        this.timestamp = timestamp;
        this.writeId = writeId;
    }

    // Getters
    public String getValue() { return value; }
    public long getTimestamp() { return timestamp; }
    public String getWriteId() { return writeId; }
}

class Replica {
    private String id;
    private Map<String, DataEntry> data;
    private Map<String, Long> versionVector;
    private boolean isAvailable;
    private ReentrantLock lock;

    public Replica(String replicaId) {
        this.id = replicaId;
        this.data = new ConcurrentHashMap<>();
        this.versionVector = new ConcurrentHashMap<>();
        this.isAvailable = true;
        this.lock = new ReentrantLock();
    }

    /**
     * å‰¯æœ¬å†™æ“ä½œ
     */
    public boolean write(String key, String value, long timestamp, String writeId) throws Exception {
        if (!isAvailable) {
            throw new Exception("å‰¯æœ¬ " + id + " ä¸å¯ç”¨");
        }

        lock.lock();
        try {
            DataEntry entry = new DataEntry(value, timestamp, writeId);
            data.put(key, entry);

            // æ›´æ–°ç‰ˆæœ¬å‘é‡
            versionVector.put(writeId, timestamp);
            return true;
        } finally {
            lock.unlock();
        }
    }

    /**
     * å‰¯æœ¬è¯»æ“ä½œ
     */
    public DataEntry read(String key) throws Exception {
        if (!isAvailable) {
            throw new Exception("å‰¯æœ¬ " + id + " ä¸å¯ç”¨");
        }

        return data.get(key);
    }

    public String getId() { return id; }
    public ReentrantLock getLock() { return lock; }
}

public class DistributedDataStore {
    private List<Replica> replicas;
    private ConsistencyLevel consistencyLevel;
    private Map<String, Long> versionVector;
    private ExecutorService executor;

    public DistributedDataStore(List<Replica> replicas, ConsistencyLevel consistencyLevel) {
        this.replicas = replicas;
        this.consistencyLevel = consistencyLevel;
        this.versionVector = new ConcurrentHashMap<>();
        this.executor = Executors.newCachedThreadPool();
    }

    /**
     * å†™æ“ä½œå®ç°ä¸åŒä¸€è‡´æ€§çº§åˆ«
     */
    public boolean write(String key, String value, String clientId) {
        long timestamp = System.currentTimeMillis();
        String writeId = UUID.randomUUID().toString();

        switch (consistencyLevel) {
            case STRONG:
                return strongConsistencyWrite(key, value, timestamp, writeId);
            case EVENTUAL:
                return eventualConsistencyWrite(key, value, timestamp, writeId);
            case WEAK:
                return weakConsistencyWrite(key, value, timestamp, writeId);
            default:
                return false;
        }
    }

    /**
     * å¼ºä¸€è‡´æ€§å†™æ“ä½œ - éœ€è¦æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
     */
    private boolean strongConsistencyWrite(String key, String value, long timestamp, String writeId) {
        int successfulWrites = 0;
        int requiredWrites = replicas.size();

        for (Replica replica : replicas) {
            try {
                replica.getLock().lock();
                try {
                    if (replica.write(key, value, timestamp, writeId)) {
                        successfulWrites++;
                    }
                } finally {
                    replica.getLock().unlock();
                }
            } catch (Exception e) {
                System.out.println("å†™å…¥å‰¯æœ¬ " + replica.getId() + " å¤±è´¥: " + e.getMessage());
            }
        }

        if (successfulWrites == requiredWrites) {
            System.out.println("å¼ºä¸€è‡´æ€§å†™å…¥æˆåŠŸ: " + key + " = " + value);
            return true;
        } else {
            // å›æ»šæ“ä½œ
            rollbackWrite(key, writeId);
            return false;
        }
    }

    /**
     * æœ€ç»ˆä¸€è‡´æ€§å†™æ“ä½œ - å¼‚æ­¥å¤åˆ¶
     */
    private boolean eventualConsistencyWrite(String key, String value, long timestamp, String writeId) {
        if (replicas.isEmpty()) return false;

        Replica primaryReplica = replicas.get(0);

        // ä¸»å‰¯æœ¬å†™å…¥
        try {
            primaryReplica.getLock().lock();
            try {
                boolean success = primaryReplica.write(key, value, timestamp, writeId);

                if (success) {
                    // å¼‚æ­¥å¤åˆ¶åˆ°å…¶ä»–å‰¯æœ¬
                    List<Replica> secondaryReplicas = replicas.subList(1, replicas.size());
                    asyncReplicate(key, value, timestamp, writeId, secondaryReplicas);
                    return true;
                }
            } finally {
                primaryReplica.getLock().unlock();
            }
        } catch (Exception e) {
            System.out.println("ä¸»å‰¯æœ¬å†™å…¥å¤±è´¥: " + e.getMessage());
        }

        return false;
    }

    /**
     * å¼±ä¸€è‡´æ€§å†™æ“ä½œ
     */
    private boolean weakConsistencyWrite(String key, String value, long timestamp, String writeId) {
        // ç®€åŒ–å®ç°ï¼šåªå†™å…¥ä¸€ä¸ªå‰¯æœ¬
        if (!replicas.isEmpty()) {
            try {
                return replicas.get(0).write(key, value, timestamp, writeId);
            } catch (Exception e) {
                System.out.println("å¼±ä¸€è‡´æ€§å†™å…¥å¤±è´¥: " + e.getMessage());
            }
        }
        return false;
    }

    /**
     * å¼‚æ­¥å¤åˆ¶åˆ°å‰¯æœ¬
     */
    private void asyncReplicate(String key, String value, long timestamp, String writeId,
                               List<Replica> replicasToUpdate) {
        for (Replica replica : replicasToUpdate) {
            executor.submit(() -> {
                try {
                    Thread.sleep(100); // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
                    replica.getLock().lock();
                    try {
                        replica.write(key, value, timestamp, writeId);
                        System.out.println("å¼‚æ­¥å¤åˆ¶åˆ°å‰¯æœ¬ " + replica.getId() + " æˆåŠŸ");
                    } finally {
                        replica.getLock().unlock();
                    }
                } catch (Exception e) {
                    System.out.println("å¼‚æ­¥å¤åˆ¶åˆ°å‰¯æœ¬ " + replica.getId() + " å¤±è´¥: " + e.getMessage());
                }
            });
        }
    }

    /**
     * å›æ»šå†™æ“ä½œ
     */
    private void rollbackWrite(String key, String writeId) {
        System.out.println("æ­£åœ¨å›æ»šå†™æ“ä½œ: " + writeId);
        // ç®€åŒ–å®ç°ï¼Œå®é™…ä¸­éœ€è¦å¤æ‚çš„å›æ»šé€»è¾‘
    }

    public void shutdown() {
        executor.shutdown();
    }

    // ä½¿ç”¨ç¤ºä¾‹
    public static void main(String[] args) throws InterruptedException {
        List<Replica> replicas = Arrays.asList(
            new Replica("replica_0"),
            new Replica("replica_1"),
            new Replica("replica_2")
        );

        // å¼ºä¸€è‡´æ€§å­˜å‚¨
        DistributedDataStore strongStore = new DistributedDataStore(replicas, ConsistencyLevel.STRONG);
        System.out.println("=== å¼ºä¸€è‡´æ€§æµ‹è¯• ===");
        strongStore.write("user:1", "Alice", "client_1");

        // æœ€ç»ˆä¸€è‡´æ€§å­˜å‚¨
        DistributedDataStore eventualStore = new DistributedDataStore(replicas, ConsistencyLevel.EVENTUAL);
        System.out.println("\n=== æœ€ç»ˆä¸€è‡´æ€§æµ‹è¯• ===");
        eventualStore.write("user:2", "Bob", "client_2");

        Thread.sleep(1000); // ç­‰å¾…å¼‚æ­¥å¤åˆ¶å®Œæˆ

        strongStore.shutdown();
        eventualStore.shutdown();
    }
}
```

#### ä¸€è‡´æ€§çº§åˆ«å¯¹æ¯”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ä¸€è‡´æ€§çº§åˆ«    â”‚ è¯»å–å»¶è¿Ÿ     â”‚ å†™å…¥å»¶è¿Ÿ     â”‚ æ•°æ®ä¸€è‡´æ€§    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å¼ºä¸€è‡´æ€§      â”‚ é«˜           â”‚ é«˜           â”‚ ç«‹å³ä¸€è‡´      â”‚
â”‚ æœ€ç»ˆä¸€è‡´æ€§    â”‚ ä½           â”‚ ä½           â”‚ å»¶è¿Ÿä¸€è‡´      â”‚
â”‚ å¼±ä¸€è‡´æ€§      â”‚ æœ€ä½         â”‚ æœ€ä½         â”‚ ä¸ä¿è¯        â”‚
â”‚ å•è°ƒä¸€è‡´æ€§    â”‚ ä¸­ç­‰         â”‚ ä¸­ç­‰         â”‚ å•è°ƒé€’å¢      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. å¯ç”¨æ€§ (Availability)

å¯ç”¨æ€§è¦æ±‚ç³»ç»Ÿåœ¨åˆç†çš„æ—¶é—´å†…å“åº”ç”¨æˆ·è¯·æ±‚ã€‚

```python
import random
import threading
import time
from datetime import datetime, timedelta

class AvailabilityManager:
    """å¯ç”¨æ€§ç®¡ç†å™¨"""

    def __init__(self, target_availability=0.99):
        self.target_availability = target_availability
        self.request_history = []
        self.downtime_periods = []
        self.circuit_breaker_state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
        self.failure_count = 0
        self.failure_threshold = 5
        self.timeout = 30  # ç§’

    def process_request(self, request):
        """å¤„ç†è¯·æ±‚å¹¶è®°å½•å¯ç”¨æ€§æŒ‡æ ‡"""
        start_time = datetime.now()

        try:
            # æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
            if self.circuit_breaker_state == "OPEN":
                if self._should_attempt_reset():
                    self.circuit_breaker_state = "HALF_OPEN"
                else:
                    raise Exception("æœåŠ¡ç†”æ–­ä¸­")

            # æ¨¡æ‹Ÿè¯·æ±‚å¤„ç†
            processing_time = self._simulate_request_processing()

            # è®°å½•æˆåŠŸè¯·æ±‚
            self.request_history.append({
                'timestamp': start_time,
                'success': True,
                'response_time': processing_time,
                'request_id': request.get('id', 'unknown')
            })

            # é‡ç½®å¤±è´¥è®¡æ•°
            if self.circuit_breaker_state == "HALF_OPEN":
                self.circuit_breaker_state = "CLOSED"
                self.failure_count = 0

            return {'status': 'success', 'data': f"å¤„ç†è¯·æ±‚ {request.get('id')}"}

        except Exception as e:
            # è®°å½•å¤±è´¥è¯·æ±‚
            self.request_history.append({
                'timestamp': start_time,
                'success': False,
                'error': str(e),
                'request_id': request.get('id', 'unknown')
            })

            # æ›´æ–°ç†”æ–­å™¨çŠ¶æ€
            self.failure_count += 1
            if self.failure_count >= self.failure_threshold:
                self.circuit_breaker_state = "OPEN"
                self.downtime_periods.append({
                    'start': datetime.now(),
                    'reason': 'è¿ç»­å¤±è´¥è§¦å‘ç†”æ–­'
                })

            raise e

    def _simulate_request_processing(self):
        """æ¨¡æ‹Ÿè¯·æ±‚å¤„ç†æ—¶é—´"""
        # 90%çš„è¯·æ±‚æ­£å¸¸å¤„ç†ï¼Œ10%å¯èƒ½è¶…æ—¶æˆ–å¤±è´¥
        if random.random() < 0.9:
            return random.uniform(0.1, 0.5)  # æ­£å¸¸å“åº”æ—¶é—´
        else:
            if random.random() < 0.5:
                time.sleep(2)  # æ¨¡æ‹Ÿè¶…æ—¶
                raise Exception("è¯·æ±‚è¶…æ—¶")
            else:
                raise Exception("æœåŠ¡å†…éƒ¨é”™è¯¯")

    def _should_attempt_reset(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å°è¯•é‡ç½®ç†”æ–­å™¨"""
        if not self.downtime_periods:
            return False

        last_downtime = self.downtime_periods[-1]
        return datetime.now() - last_downtime['start'] > timedelta(seconds=self.timeout)

    def calculate_availability(self, time_window_hours=24):
        """è®¡ç®—å¯ç”¨æ€§æŒ‡æ ‡"""
        current_time = datetime.now()
        window_start = current_time - timedelta(hours=time_window_hours)

        # è¿‡æ»¤æ—¶é—´çª—å£å†…çš„è¯·æ±‚
        recent_requests = [
            req for req in self.request_history
            if req['timestamp'] >= window_start
        ]

        if not recent_requests:
            return 1.0

        successful_requests = sum(1 for req in recent_requests if req['success'])
        total_requests = len(recent_requests)

        availability = successful_requests / total_requests

        return {
            'availability': availability,
            'total_requests': total_requests,
            'successful_requests': successful_requests,
            'failed_requests': total_requests - successful_requests,
            'meets_sla': availability >= self.target_availability
        }

# å¯ç”¨æ€§æµ‹è¯•
def availability_test():
    """å¯ç”¨æ€§æµ‹è¯•å‡½æ•°"""
    manager = AvailabilityManager(target_availability=0.95)

    # æ¨¡æ‹Ÿ1000ä¸ªå¹¶å‘è¯·æ±‚
    def send_requests():
        for i in range(100):
            try:
                request = {'id': f'req_{i}', 'data': f'test_data_{i}'}
                result = manager.process_request(request)
                print(f"âœ“ è¯·æ±‚ {i} æˆåŠŸ")
            except Exception as e:
                print(f"âœ— è¯·æ±‚ {i} å¤±è´¥: {e}")

            time.sleep(0.01)  # æ¨¡æ‹Ÿè¯·æ±‚é—´éš”

    # å¯åŠ¨å¤šä¸ªçº¿ç¨‹æ¨¡æ‹Ÿå¹¶å‘
    threads = []
    for i in range(10):
        thread = threading.Thread(target=send_requests)
        threads.append(thread)
        thread.start()

    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for thread in threads:
        thread.join()

    # è®¡ç®—å¯ç”¨æ€§æŒ‡æ ‡
    metrics = manager.calculate_availability()
    print(f"\n=== å¯ç”¨æ€§æŒ‡æ ‡ ===")
    print(f"å¯ç”¨æ€§: {metrics['availability']:.4f} ({metrics['availability']*100:.2f}%)")
    print(f"æ€»è¯·æ±‚æ•°: {metrics['total_requests']}")
    print(f"æˆåŠŸè¯·æ±‚æ•°: {metrics['successful_requests']}")
    print(f"å¤±è´¥è¯·æ±‚æ•°: {metrics['failed_requests']}")
    print(f"æ»¡è¶³SLA: {metrics['meets_sla']}")

# è¿è¡Œæµ‹è¯•
availability_test()
```

### 3. åˆ†åŒºå®¹é”™æ€§ (Partition Tolerance)

åˆ†åŒºå®¹é”™æ€§è¦æ±‚ç³»ç»Ÿåœ¨ç½‘ç»œåˆ†åŒºå‘ç”Ÿæ—¶ä»èƒ½ç»§ç»­å·¥ä½œã€‚

```python
import random
import time
from collections import defaultdict

class NetworkPartition:
    """ç½‘ç»œåˆ†åŒºæ¨¡æ‹Ÿå™¨"""

    def __init__(self, nodes):
        self.nodes = nodes
        self.partitions = [set(nodes)]  # åˆå§‹æ—¶æ‰€æœ‰èŠ‚ç‚¹åœ¨åŒä¸€åˆ†åŒº
        self.message_loss_rate = 0.0

    def create_partition(self, partition1, partition2):
        """åˆ›å»ºç½‘ç»œåˆ†åŒº"""
        self.partitions = [set(partition1), set(partition2)]
        print(f"ç½‘ç»œåˆ†åŒºåˆ›å»º: {partition1} | {partition2}")

    def heal_partition(self):
        """ä¿®å¤ç½‘ç»œåˆ†åŒº"""
        self.partitions = [set(self.nodes)]
        print("ç½‘ç»œåˆ†åŒºå·²ä¿®å¤")

    def can_communicate(self, node1, node2):
        """æ£€æŸ¥ä¸¤ä¸ªèŠ‚ç‚¹æ˜¯å¦å¯ä»¥é€šä¿¡"""
        # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€åˆ†åŒº
        for partition in self.partitions:
            if node1 in partition and node2 in partition:
                # æ¨¡æ‹Ÿç½‘ç»œä¸¢åŒ…
                return random.random() > self.message_loss_rate
        return False

class PartitionTolerantSystem:
    """åˆ†åŒºå®¹é”™ç³»ç»Ÿå®ç°"""

    def __init__(self, nodes, quorum_size):
        self.nodes = nodes
        self.quorum_size = quorum_size
        self.data = defaultdict(dict)  # node_id -> {key: value}
        self.network = NetworkPartition(nodes)
        self.leader = nodes[0]

    def write(self, key, value, client_node):
        """åˆ†åŒºå®¹é”™çš„å†™æ“ä½œ"""
        print(f"\nå°è¯•å†™å…¥ {key} = {value} (æ¥è‡ªèŠ‚ç‚¹ {client_node})")

        # æŸ¥æ‰¾å¯è¾¾çš„èŠ‚ç‚¹
        reachable_nodes = self._find_reachable_nodes(client_node)

        if len(reachable_nodes) < self.quorum_size:
            print(f"å¯è¾¾èŠ‚ç‚¹æ•° ({len(reachable_nodes)}) å°äºæ³•å®šäººæ•° ({self.quorum_size})")
            return False

        # å‘å¯è¾¾èŠ‚ç‚¹å†™å…¥æ•°æ®
        successful_writes = 0
        for node in reachable_nodes:
            if self._write_to_node(node, key, value):
                successful_writes += 1

        success = successful_writes >= self.quorum_size
        print(f"å†™å…¥ç»“æœ: {successful_writes}/{len(reachable_nodes)} èŠ‚ç‚¹æˆåŠŸ, éœ€è¦ {self.quorum_size}")

        return success

    def read(self, key, client_node):
        """åˆ†åŒºå®¹é”™çš„è¯»æ“ä½œ"""
        print(f"\nå°è¯•è¯»å– {key} (æ¥è‡ªèŠ‚ç‚¹ {client_node})")

        reachable_nodes = self._find_reachable_nodes(client_node)

        if len(reachable_nodes) < self.quorum_size:
            print(f"å¯è¾¾èŠ‚ç‚¹æ•° ({len(reachable_nodes)}) å°äºæ³•å®šäººæ•° ({self.quorum_size})")
            return None

        # ä»å¯è¾¾èŠ‚ç‚¹è¯»å–æ•°æ®
        values = []
        for node in reachable_nodes[:self.quorum_size]:
            value = self._read_from_node(node, key)
            if value is not None:
                values.append(value)

        if values:
            # è¿”å›æœ€æ–°å€¼ï¼ˆç®€åŒ–å®ç°ï¼‰
            result = values[-1]
            print(f"è¯»å–ç»“æœ: {result}")
            return result
        else:
            print("è¯»å–å¤±è´¥: æœªæ‰¾åˆ°æ•°æ®")
            return None

    def _find_reachable_nodes(self, from_node):
        """æŸ¥æ‰¾ä»æŒ‡å®šèŠ‚ç‚¹å¯è¾¾çš„æ‰€æœ‰èŠ‚ç‚¹"""
        reachable = []
        for node in self.nodes:
            if node == from_node or self.network.can_communicate(from_node, node):
                reachable.append(node)

        print(f"ä»èŠ‚ç‚¹ {from_node} å¯è¾¾çš„èŠ‚ç‚¹: {reachable}")
        return reachable

    def _write_to_node(self, node, key, value):
        """å‘æŒ‡å®šèŠ‚ç‚¹å†™å…¥æ•°æ®"""
        try:
            # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
            time.sleep(0.01)
            self.data[node][key] = {
                'value': value,
                'timestamp': time.time()
            }
            print(f"  âœ“ å†™å…¥èŠ‚ç‚¹ {node} æˆåŠŸ")
            return True
        except Exception as e:
            print(f"  âœ— å†™å…¥èŠ‚ç‚¹ {node} å¤±è´¥: {e}")
            return False

    def _read_from_node(self, node, key):
        """ä»æŒ‡å®šèŠ‚ç‚¹è¯»å–æ•°æ®"""
        try:
            time.sleep(0.01)
            data = self.data[node].get(key)
            if data:
                print(f"  âœ“ ä»èŠ‚ç‚¹ {node} è¯»å–: {data['value']}")
                return data['value']
            else:
                print(f"  - èŠ‚ç‚¹ {node} æ— æ•°æ®")
                return None
        except Exception as e:
            print(f"  âœ— ä»èŠ‚ç‚¹ {node} è¯»å–å¤±è´¥: {e}")
            return None

# åˆ†åŒºå®¹é”™æµ‹è¯•
def partition_tolerance_test():
    """åˆ†åŒºå®¹é”™æµ‹è¯•"""
    nodes = ['A', 'B', 'C', 'D', 'E']
    system = PartitionTolerantSystem(nodes, quorum_size=3)

    print("=== æ­£å¸¸æƒ…å†µä¸‹çš„è¯»å†™æµ‹è¯• ===")
    system.write("user:1", "Alice", "A")
    system.read("user:1", "B")

    print("\n=== åˆ›å»ºç½‘ç»œåˆ†åŒº ===")
    system.network.create_partition(['A', 'B'], ['C', 'D', 'E'])

    print("\n=== åˆ†åŒºåçš„å†™å…¥æµ‹è¯• ===")
    # å¤§åˆ†åŒºï¼ˆ3ä¸ªèŠ‚ç‚¹ï¼‰å¯ä»¥ç»§ç»­æœåŠ¡
    system.write("user:2", "Bob", "C")

    # å°åˆ†åŒºï¼ˆ2ä¸ªèŠ‚ç‚¹ï¼‰æ— æ³•è¾¾åˆ°æ³•å®šäººæ•°
    system.write("user:3", "Charlie", "A")

    print("\n=== åˆ†åŒºåçš„è¯»å–æµ‹è¯• ===")
    system.read("user:1", "C")  # å¤§åˆ†åŒºè¯»å–
    system.read("user:2", "A")  # å°åˆ†åŒºè¯»å–

    print("\n=== ä¿®å¤ç½‘ç»œåˆ†åŒº ===")
    system.network.heal_partition()

    print("\n=== åˆ†åŒºä¿®å¤åçš„æµ‹è¯• ===")
    system.write("user:4", "David", "A")
    system.read("user:4", "E")

# è¿è¡Œæµ‹è¯•
partition_tolerance_test()
```

## CAPç»„åˆåˆ†æ

### 1. CPç³»ç»Ÿ (ä¸€è‡´æ€§ + åˆ†åŒºå®¹é”™)

```python
class CPSystem:
    """CPç³»ç»Ÿå®ç° - ç‰ºç‰²å¯ç”¨æ€§ä¿è¯ä¸€è‡´æ€§"""

    def __init__(self, nodes):
        self.nodes = nodes
        self.master = nodes[0]
        self.data = {}
        self.is_available = True

    def write(self, key, value):
        """å¼ºä¸€è‡´æ€§å†™å…¥"""
        if not self.is_available:
            raise Exception("ç³»ç»Ÿä¸å¯ç”¨ - ç½‘ç»œåˆ†åŒºå¯¼è‡´æ— æ³•ä¿è¯ä¸€è‡´æ€§")

        # å¿…é¡»åœ¨æ‰€æœ‰èŠ‚ç‚¹æˆåŠŸå†™å…¥æ‰è¿”å›æˆåŠŸ
        successful_writes = 0
        for node in self.nodes:
            try:
                if self._write_to_node(node, key, value):
                    successful_writes += 1
            except Exception:
                # ä»»ä½•èŠ‚ç‚¹å¤±è´¥éƒ½ä¼šå¯¼è‡´æ•´ä¸ªå†™å…¥å¤±è´¥
                self.is_available = False
                raise Exception("å†™å…¥å¤±è´¥ - ç³»ç»Ÿè¿›å…¥ä¸å¯ç”¨çŠ¶æ€")

        if successful_writes == len(self.nodes):
            self.data[key] = value
            return True
        else:
            self.is_available = False
            raise Exception("å†™å…¥å¤±è´¥ - æ— æ³•ä¿è¯ä¸€è‡´æ€§")

    def read(self, key):
        """å¼ºä¸€è‡´æ€§è¯»å–"""
        if not self.is_available:
            raise Exception("ç³»ç»Ÿä¸å¯ç”¨")

        return self.data.get(key)

# CPç³»ç»Ÿç¤ºä¾‹ï¼šMongoDBã€Redis Cluster
print("=== CPç³»ç»Ÿç¤ºä¾‹ ===")
cp_system = CPSystem(['node1', 'node2', 'node3'])
try:
    cp_system.write("key1", "value1")
    print(f"è¯»å–ç»“æœ: {cp_system.read('key1')}")
except Exception as e:
    print(f"CPç³»ç»Ÿé”™è¯¯: {e}")
```

### 2. APç³»ç»Ÿ (å¯ç”¨æ€§ + åˆ†åŒºå®¹é”™)

```python
class APSystem:
    """APç³»ç»Ÿå®ç° - ç‰ºç‰²ä¸€è‡´æ€§ä¿è¯å¯ç”¨æ€§"""

    def __init__(self, nodes):
        self.nodes = nodes
        self.data = {node: {} for node in nodes}
        self.vector_clocks = {node: {} for node in nodes}

    def write(self, key, value, preferred_node=None):
        """æœ€ç»ˆä¸€è‡´æ€§å†™å…¥"""
        target_node = preferred_node or self.nodes[0]

        # æ›´æ–°å‘é‡æ—¶é’Ÿ
        if key not in self.vector_clocks[target_node]:
            self.vector_clocks[target_node][key] = 0
        self.vector_clocks[target_node][key] += 1

        # å†™å…¥ç›®æ ‡èŠ‚ç‚¹
        self.data[target_node][key] = {
            'value': value,
            'timestamp': time.time(),
            'vector_clock': self.vector_clocks[target_node][key]
        }

        # å¼‚æ­¥å¤åˆ¶åˆ°å…¶ä»–å¯è¾¾èŠ‚ç‚¹
        self._async_replicate(key, value, target_node)

        print(f"å†™å…¥æˆåŠŸåˆ°èŠ‚ç‚¹ {target_node}")
        return True

    def read(self, key, preferred_node=None):
        """è¯»å–ï¼ˆå¯èƒ½ä¸ä¸€è‡´ï¼‰"""
        target_node = preferred_node or self.nodes[0]

        data = self.data[target_node].get(key)
        if data:
            print(f"ä»èŠ‚ç‚¹ {target_node} è¯»å–: {data['value']}")
            return data['value']
        else:
            print(f"èŠ‚ç‚¹ {target_node} æ²¡æœ‰é”® {key}")
            return None

    def _async_replicate(self, key, value, source_node):
        """å¼‚æ­¥å¤åˆ¶åˆ°å…¶ä»–èŠ‚ç‚¹"""
        import threading

        def replicate():
            for node in self.nodes:
                if node != source_node:
                    try:
                        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
                        time.sleep(random.uniform(0.1, 0.5))

                        source_data = self.data[source_node][key]
                        self.data[node][key] = source_data.copy()
                        print(f"  å¼‚æ­¥å¤åˆ¶åˆ°èŠ‚ç‚¹ {node}")
                    except Exception as e:
                        print(f"  å¤åˆ¶åˆ°èŠ‚ç‚¹ {node} å¤±è´¥: {e}")

        thread = threading.Thread(target=replicate)
        thread.start()

# APç³»ç»Ÿç¤ºä¾‹ï¼šCassandraã€DynamoDB
print("\n=== APç³»ç»Ÿç¤ºä¾‹ ===")
ap_system = APSystem(['node1', 'node2', 'node3'])

ap_system.write("key1", "value1", "node1")
time.sleep(0.1)  # ç­‰å¾…å¼‚æ­¥å¤åˆ¶

# è¯»å–å¯èƒ½å¾—åˆ°ä¸åŒç»“æœ
ap_system.read("key1", "node1")
ap_system.read("key1", "node2")
```

## å®é™…ç³»ç»Ÿåˆ†æ

### æ•°æ®åº“ç³»ç»ŸCAPé€‰æ‹©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç³»ç»Ÿç±»å‹         â”‚ ä¸€è‡´æ€§æ¨¡å‹   â”‚ å¯ç”¨æ€§ç­–ç•¥    â”‚ åˆ†åŒºå®¹é”™æ–¹æ¡ˆ  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RDBMS           â”‚ ACIDå¼ºä¸€è‡´   â”‚ ä¸»ä»å¤åˆ¶     â”‚ åˆ†åŒºæ—¶åœæœåŠ¡  â”‚
â”‚ MongoDB         â”‚ å¯è°ƒä¸€è‡´æ€§   â”‚ å‰¯æœ¬é›†       â”‚ ä¸»èŠ‚ç‚¹é€‰ä¸¾   â”‚
â”‚ Cassandra       â”‚ æœ€ç»ˆä¸€è‡´æ€§   â”‚ å¤šä¸»å¤åˆ¶     â”‚ Gossipåè®®   â”‚
â”‚ Redis Cluster   â”‚ å¼ºä¸€è‡´æ€§     â”‚ æ•…éšœè½¬ç§»     â”‚ é›†ç¾¤é‡é…ç½®   â”‚
â”‚ Elasticsearch   â”‚ æœ€ç»ˆä¸€è‡´æ€§   â”‚ åˆ†ç‰‡å¤åˆ¶     â”‚ è„‘è£‚æ£€æµ‹     â”‚
â”‚ Kafka           â”‚ é¡ºåºä¸€è‡´æ€§   â”‚ åˆ†åŒºå¤åˆ¶     â”‚ ISRæœºåˆ¶      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### çœŸå®æ¡ˆä¾‹åˆ†æ

```python
class DatabaseCAPAnalysis:
    """æ•°æ®åº“CAPç‰¹æ€§åˆ†æ"""

    @staticmethod
    def analyze_mongodb():
        """MongoDB CAPåˆ†æ"""
        return {
            'type': 'CPç³»ç»Ÿ',
            'consistency': 'å¯é…ç½®ï¼ˆé»˜è®¤å¼ºä¸€è‡´æ€§ï¼‰',
            'availability': 'ä¸»èŠ‚ç‚¹æ•…éšœæ—¶çŸ­æš‚ä¸å¯ç”¨',
            'partition_tolerance': 'é€šè¿‡å‰¯æœ¬é›†å®ç°',
            'trade_offs': [
                'ä¸»èŠ‚ç‚¹æ•…éšœæ—¶å†™æ“ä½œä¸å¯ç”¨',
                'æ¬¡èŠ‚ç‚¹å¯æä¾›è¯»æ“ä½œ',
                'è‡ªåŠ¨æ•…éšœè½¬ç§»æ¢å¤å¯ç”¨æ€§'
            ],
            'use_cases': [
                'éœ€è¦å¼ºä¸€è‡´æ€§çš„åº”ç”¨',
                'æ–‡æ¡£å‹æ•°æ®å­˜å‚¨',
                'OLTPç³»ç»Ÿ'
            ]
        }

    @staticmethod
    def analyze_cassandra():
        """Cassandra CAPåˆ†æ"""
        return {
            'type': 'APç³»ç»Ÿ',
            'consistency': 'æœ€ç»ˆä¸€è‡´æ€§ï¼ˆå¯è°ƒèŠ‚ï¼‰',
            'availability': 'æé«˜å¯ç”¨æ€§',
            'partition_tolerance': 'Gossipåè®®å¤„ç†åˆ†åŒº',
            'trade_offs': [
                'è¯»å†™å¯èƒ½è¿”å›è¿‡æœŸæ•°æ®',
                'éœ€è¦åº”ç”¨å±‚å¤„ç†å†²çª',
                'æ•°æ®æœ€ç»ˆä¼šä¸€è‡´'
            ],
            'use_cases': [
                'é«˜å¯ç”¨æ€§è¦æ±‚',
                'å¤§è§„æ¨¡åˆ†å¸ƒå¼ç³»ç»Ÿ',
                'æ—¶é—´åºåˆ—æ•°æ®'
            ]
        }

    @staticmethod
    def analyze_redis_cluster():
        """Redis Cluster CAPåˆ†æ"""
        return {
            'type': 'CPç³»ç»Ÿ',
            'consistency': 'å¼ºä¸€è‡´æ€§',
            'availability': 'åˆ†ç‰‡æ•…éšœæ—¶éƒ¨åˆ†ä¸å¯ç”¨',
            'partition_tolerance': 'é›†ç¾¤é‡é…ç½®',
            'trade_offs': [
                'ä¸»èŠ‚ç‚¹æ•…éšœå½±å“å¯¹åº”åˆ†ç‰‡',
                'é›†ç¾¤é‡é…ç½®æœŸé—´çŸ­æš‚ä¸å¯ç”¨',
                'ä¿è¯æ•°æ®å¼ºä¸€è‡´æ€§'
            ],
            'use_cases': [
                'ç¼“å­˜ç³»ç»Ÿ',
                'ä¼šè¯å­˜å‚¨',
                'å®æ—¶è®¡ç®—'
            ]
        }

# è¾“å‡ºåˆ†æç»“æœ
analysis = DatabaseCAPAnalysis()
systems = ['mongodb', 'cassandra', 'redis_cluster']

for system in systems:
    result = getattr(analysis, f'analyze_{system}')()
    print(f"\n=== {system.upper()} CAPåˆ†æ ===")
    for key, value in result.items():
        if isinstance(value, list):
            print(f"{key}:")
            for item in value:
                print(f"  - {item}")
        else:
            print(f"{key}: {value}")
```

## æ¶æ„è®¾è®¡æŒ‡å¯¼

### 1. ç³»ç»Ÿé€‰å‹å†³ç­–æ ‘

```
é€‰æ‹©åˆ†å¸ƒå¼ç³»ç»Ÿæ¶æ„
         â”‚
         â–¼
    æ˜¯å¦å¯æ¥å—åˆ†åŒºï¼Ÿ
         â”‚
      â”Œâ”€â”€â”´â”€â”€â”
     å¦â”‚    â”‚æ˜¯
      â”‚    â”‚
      â–¼    â–¼
   å•æœºç³»ç»Ÿ  æ˜¯å¦ä¼˜å…ˆä¸€è‡´æ€§ï¼Ÿ
   (CA)     â”‚
           â”Œâ”´â”€â”
          æ˜¯â”‚ â”‚å¦
           â”‚ â”‚
           â–¼ â–¼
        CPç³»ç»Ÿ APç³»ç»Ÿ
```

### 2. å®è·µæŒ‡å¯¼åŸåˆ™

```python
class CAPGuidelines:
    """CAPç†è®ºå®è·µæŒ‡å¯¼"""

    @staticmethod
    def choose_consistency_level(requirements):
        """é€‰æ‹©ä¸€è‡´æ€§çº§åˆ«"""
        if requirements.get('financial_data'):
            return 'STRONG'
        elif requirements.get('user_experience'):
            return 'EVENTUAL'
        elif requirements.get('analytics'):
            return 'WEAK'
        else:
            return 'MONOTONIC'

    @staticmethod
    def design_availability_strategy(sla_requirement):
        """è®¾è®¡å¯ç”¨æ€§ç­–ç•¥"""
        if sla_requirement >= 0.9999:  # 99.99%
            return {
                'strategy': 'multi_region_active_active',
                'components': [
                    'å¤šåœ°åŸŸéƒ¨ç½²',
                    'è‡ªåŠ¨æ•…éšœè½¬ç§»',
                    'å¥åº·æ£€æŸ¥',
                    'æµé‡è·¯ç”±'
                ]
            }
        elif sla_requirement >= 0.999:  # 99.9%
            return {
                'strategy': 'active_passive',
                'components': [
                    'ä¸»å¤‡éƒ¨ç½²',
                    'å¿ƒè·³æ£€æµ‹',
                    'å¿«é€Ÿåˆ‡æ¢'
                ]
            }
        else:
            return {
                'strategy': 'single_region',
                'components': [
                    'æœ¬åœ°å†—ä½™',
                    'åŸºæœ¬ç›‘æ§'
                ]
            }

    @staticmethod
    def partition_tolerance_design(network_reliability):
        """åˆ†åŒºå®¹é”™è®¾è®¡"""
        if network_reliability < 0.95:
            return {
                'approach': 'aggressive_partition_handling',
                'techniques': [
                    'Quorumæœºåˆ¶',
                    'å‘é‡æ—¶é’Ÿ',
                    'å†²çªè§£å†³',
                    'åç†µæœºåˆ¶'
                ]
            }
        else:
            return {
                'approach': 'basic_partition_handling',
                'techniques': [
                    'ä¸»ä»å¤åˆ¶',
                    'æ•…éšœæ£€æµ‹',
                    'è‡ªåŠ¨æ¢å¤'
                ]
            }

# ä½¿ç”¨ç¤ºä¾‹
guidelines = CAPGuidelines()

# ç”µå•†ç³»ç»Ÿéœ€æ±‚åˆ†æ
ecommerce_requirements = {
    'financial_data': True,
    'user_experience': True,
    'sla_requirement': 0.999,
    'network_reliability': 0.98
}

print("=== ç”µå•†ç³»ç»ŸCAPè®¾è®¡å»ºè®® ===")
consistency = guidelines.choose_consistency_level(ecommerce_requirements)
availability = guidelines.design_availability_strategy(ecommerce_requirements['sla_requirement'])
partition = guidelines.partition_tolerance_design(ecommerce_requirements['network_reliability'])

print(f"ä¸€è‡´æ€§é€‰æ‹©: {consistency}")
print(f"å¯ç”¨æ€§ç­–ç•¥: {availability['strategy']}")
print(f"åˆ†åŒºå®¹é”™æ–¹æ¡ˆ: {partition['approach']}")
```

## ç°ä»£å‘å±•è¶‹åŠ¿

### 1. PACELCå®šç†

CAPç†è®ºçš„æ‰©å±•ï¼Œè€ƒè™‘ç½‘ç»œæ­£å¸¸æ—¶çš„æƒè¡¡ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PACELC å®šç†                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ P â†’ A vs C (åˆ†åŒºæ—¶: å¯ç”¨æ€§ vs ä¸€è‡´æ€§) â”‚
â”‚ E â†’ L vs C (æ­£å¸¸æ—¶: å»¶è¿Ÿ vs ä¸€è‡´æ€§)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç³»ç»Ÿåˆ†ç±»ï¼š
â€¢ PA/EL: Dynamo, Cassandra
â€¢ PA/EC: MongoDB, VoltDB
â€¢ PC/EL: Yahoo! PNUTS
â€¢ PC/EC: HBase, Redis Cluster
```

### 2. æ–°å…´æ¶æ„æ¨¡å¼

```python
class ModernCAPEvolution:
    """ç°ä»£CAPç†è®ºæ¼”è¿›"""

    @staticmethod
    def cqrs_pattern():
        """å‘½ä»¤æŸ¥è¯¢è´£ä»»åˆ†ç¦»"""
        return {
            'description': 'è¯»å†™åˆ†ç¦»ï¼Œä¸åŒä¸€è‡´æ€§è¦æ±‚',
            'write_side': 'CPç³»ç»Ÿï¼ˆå¼ºä¸€è‡´æ€§ï¼‰',
            'read_side': 'APç³»ç»Ÿï¼ˆæœ€ç»ˆä¸€è‡´æ€§ï¼‰',
            'benefits': [
                'è¯»å†™æ€§èƒ½ç‹¬ç«‹ä¼˜åŒ–',
                'ä¸åŒä¸€è‡´æ€§éœ€æ±‚',
                'å¤æ‚æŸ¥è¯¢æ”¯æŒ'
            ]
        }

    @staticmethod
    def event_sourcing():
        """äº‹ä»¶æº¯æº"""
        return {
            'description': 'åŸºäºäº‹ä»¶çš„çŠ¶æ€é‡å»º',
            'consistency': 'äº‹ä»¶é¡ºåºä¸€è‡´æ€§',
            'availability': 'é«˜å¯ç”¨äº‹ä»¶å­˜å‚¨',
            'partition_tolerance': 'äº‹ä»¶å¤åˆ¶å®¹é”™',
            'benefits': [
                'å®Œæ•´å†å²è®°å½•',
                'æ—¶é—´æ—…è¡Œè°ƒè¯•',
                'å®¡è®¡è¿½è¸ª'
            ]
        }

    @staticmethod
    def saga_pattern():
        """Sagaæ¨¡å¼"""
        return {
            'description': 'åˆ†å¸ƒå¼äº‹åŠ¡æœ€ç»ˆä¸€è‡´æ€§',
            'approach': 'è¡¥å¿æœºåˆ¶å¤„ç†å¤±è´¥',
            'trade_offs': [
                'ç‰ºç‰²å³æ—¶ä¸€è‡´æ€§',
                'è·å¾—é«˜å¯ç”¨æ€§',
                'å¤„ç†ç½‘ç»œåˆ†åŒº'
            ]
        }

modern_cap = ModernCAPEvolution()
patterns = ['cqrs_pattern', 'event_sourcing', 'saga_pattern']

print("=== ç°ä»£CAPæ¶æ„æ¨¡å¼ ===")
for pattern in patterns:
    result = getattr(modern_cap, pattern)()
    print(f"\n{pattern.upper().replace('_', ' ')}:")
    for key, value in result.items():
        if isinstance(value, list):
            print(f"  {key}:")
            for item in value:
                print(f"    - {item}")
        else:
            print(f"  {key}: {value}")
```

## æ€§èƒ½æµ‹è¯•ä¸ç›‘æ§

### 1. CAPæŒ‡æ ‡ç›‘æ§

```python
import psutil
import time
from datetime import datetime

class CAPMetricsMonitor:
    """CAPæŒ‡æ ‡ç›‘æ§"""

    def __init__(self):
        self.metrics = {
            'consistency': [],
            'availability': [],
            'partition_tolerance': []
        }

    def measure_consistency_lag(self, primary_value, replica_values):
        """æµ‹é‡ä¸€è‡´æ€§å»¶è¿Ÿ"""
        inconsistent_replicas = 0
        max_lag = 0

        for replica_value in replica_values:
            if replica_value != primary_value:
                inconsistent_replicas += 1
                # ç®€åŒ–çš„å»¶è¿Ÿè®¡ç®—
                lag = abs(hash(replica_value) - hash(primary_value)) / 1000000
                max_lag = max(max_lag, lag)

        consistency_ratio = 1 - (inconsistent_replicas / len(replica_values))

        self.metrics['consistency'].append({
            'timestamp': datetime.now(),
            'consistency_ratio': consistency_ratio,
            'max_lag_ms': max_lag,
            'inconsistent_replicas': inconsistent_replicas
        })

        return consistency_ratio

    def measure_availability(self, successful_requests, total_requests):
        """æµ‹é‡ç³»ç»Ÿå¯ç”¨æ€§"""
        availability = successful_requests / total_requests if total_requests > 0 else 0

        self.metrics['availability'].append({
            'timestamp': datetime.now(),
            'availability': availability,
            'successful_requests': successful_requests,
            'total_requests': total_requests
        })

        return availability

    def measure_partition_impact(self, nodes_reachable, total_nodes):
        """æµ‹é‡åˆ†åŒºå½±å“"""
        partition_ratio = nodes_reachable / total_nodes

        self.metrics['partition_tolerance'].append({
            'timestamp': datetime.now(),
            'partition_ratio': partition_ratio,
            'reachable_nodes': nodes_reachable,
            'total_nodes': total_nodes
        })

        return partition_ratio

    def generate_report(self):
        """ç”ŸæˆCAPæŒ‡æ ‡æŠ¥å‘Š"""
        report = {}

        for metric_type, measurements in self.metrics.items():
            if measurements:
                latest = measurements[-1]
                avg_value = sum(m.get(f'{metric_type.split("_")[0]}_ratio',
                                   m.get('availability', 0)) for m in measurements) / len(measurements)

                report[metric_type] = {
                    'latest': latest,
                    'average': avg_value,
                    'measurements_count': len(measurements)
                }

        return report

# ç›‘æ§ä½¿ç”¨ç¤ºä¾‹
monitor = CAPMetricsMonitor()

# æ¨¡æ‹Ÿä¸€ç³»åˆ—æµ‹é‡
for i in range(10):
    # ä¸€è‡´æ€§æµ‹é‡
    primary = f"value_{i}"
    replicas = [f"value_{i}" if random.random() > 0.1 else f"old_value_{i-1}" for _ in range(3)]
    consistency = monitor.measure_consistency_lag(primary, replicas)

    # å¯ç”¨æ€§æµ‹é‡
    success = random.randint(95, 100)
    total = 100
    availability = monitor.measure_availability(success, total)

    # åˆ†åŒºå®¹é”™æµ‹é‡
    reachable = random.randint(3, 5)
    total_nodes = 5
    partition_tolerance = monitor.measure_partition_impact(reachable, total_nodes)

    time.sleep(0.1)

# ç”ŸæˆæŠ¥å‘Š
report = monitor.generate_report()
print("=== CAPæŒ‡æ ‡ç›‘æ§æŠ¥å‘Š ===")
for metric, data in report.items():
    print(f"\n{metric.upper()}:")
    print(f"  æœ€æ–°å€¼: {data['latest']}")
    print(f"  å¹³å‡å€¼: {data['average']:.4f}")
    print(f"  æµ‹é‡æ¬¡æ•°: {data['measurements_count']}")
```

## æ€»ç»“

CAPç†è®ºä¸ºåˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡æä¾›äº†é‡è¦çš„ç†è®ºæŒ‡å¯¼ï¼š

### æ ¸å¿ƒæ´å¯Ÿ

1. **æƒè¡¡æœ¬è´¨**ï¼šåˆ†å¸ƒå¼ç³»ç»Ÿå¿…é¡»åœ¨ä¸€è‡´æ€§ã€å¯ç”¨æ€§å’Œåˆ†åŒºå®¹é”™ä¹‹é—´åšå‡ºæƒè¡¡
2. **ç°å®çº¦æŸ**ï¼šç½‘ç»œåˆ†åŒºä¸å¯é¿å…ï¼Œå¿…é¡»åœ¨Cå’ŒAä¹‹é—´é€‰æ‹©
3. **è®¾è®¡æŒ‡å¯¼**ï¼šæ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„CAPç»„åˆ

### å®è·µå»ºè®®

```
ä¸šåŠ¡åœºæ™¯ â†’ CAPé€‰æ‹©
â”œâ”€ é‡‘èç³»ç»Ÿ â†’ CP (å¼ºä¸€è‡´æ€§)
â”œâ”€ ç¤¾äº¤åª’ä½“ â†’ AP (é«˜å¯ç”¨æ€§)
â”œâ”€ ç”µå•†å¹³å° â†’ æ··åˆæ¶æ„
â””â”€ ç‰©è”ç½‘ â†’ AP (å®¹å¿ä¸ä¸€è‡´)
```

### æŠ€æœ¯æ¼”è¿›

CAPç†è®ºç»§ç»­æŒ‡å¯¼ç€ç°ä»£åˆ†å¸ƒå¼ç³»ç»Ÿçš„å‘å±•ï¼Œä»ä¼ ç»Ÿçš„æ•°æ®åº“åˆ°å¾®æœåŠ¡æ¶æ„ï¼Œä»åŒºå—é“¾åˆ°è¾¹ç¼˜è®¡ç®—ï¼Œç†è§£CAPæƒè¡¡å¯¹äºæ„å»ºå¯é çš„åˆ†å¸ƒå¼ç³»ç»Ÿè‡³å…³é‡è¦ã€‚

## å‚è€ƒèµ„æ–™

1. Brewer, E. (2000). Towards robust distributed systems
2. Gilbert, S., & Lynch, N. (2002). Brewer's conjecture and the feasibility of consistent, available, partition-tolerant web services
3. Abadi, D. (2012). Consistency tradeoffs in modern distributed database system design